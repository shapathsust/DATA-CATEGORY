{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'Accident':\n",
      "  . Most correlated unigrams:\n",
      ". থল\n",
      ". উপজ\n",
      "  . Most correlated bigrams:\n",
      ". ঘটন ঘট\n",
      ". ঘটন থল\n",
      "# 'Art':\n",
      "  . Most correlated unigrams:\n",
      ". সমক\n",
      ". ছদ\n",
      "  . Most correlated bigrams:\n",
      ". অভ নয়\n",
      ". রচ ছদ\n",
      "# 'Crime':\n",
      "  . Most correlated unigrams:\n",
      ". ইউএনও\n",
      ". নজনক\n",
      "  . Most correlated bigrams:\n",
      ". কর গতক\n",
      ". গতক শন\n",
      "# 'Economics':\n",
      "  . Most correlated unigrams:\n",
      ". এসই\n",
      ". এসইত\n",
      "  . Most correlated bigrams:\n",
      ". এসই চক\n",
      ". পয় হয়\n",
      "# 'Education':\n",
      "  . Most correlated unigrams:\n",
      ". জনশ\n",
      ". ১ম\n",
      "  . Most correlated bigrams:\n",
      ". চন রশ\n",
      ". রশ তর\n",
      "# 'Entertainment':\n",
      "  . Most correlated unigrams:\n",
      ". যচ\n",
      ". চলচ\n",
      "  . Most correlated bigrams:\n",
      ". অভ নয়\n",
      ". অভ নয\n",
      "# 'Environment':\n",
      "  . Most correlated unigrams:\n",
      ". দরবন\n",
      ". খনন\n",
      "  . Most correlated bigrams:\n",
      ". অধ দপ\n",
      ". নদ রব\n",
      "# 'International':\n",
      "  . Most correlated unigrams:\n",
      ". পরম\n",
      ". আইএস\n",
      "  . Most correlated bigrams:\n",
      ". ২০১৮ বক\n",
      ". ইসল আইএস\n",
      "# 'Opinion':\n",
      "  . Most correlated unigrams:\n",
      ". অবম\n",
      ". জনকণ\n",
      "  . Most correlated bigrams:\n",
      ". মত মত\n",
      ". অবম নন\n",
      "# 'Politics':\n",
      "  . Most correlated unigrams:\n",
      ". আওয়\n",
      ". এনপ\n",
      "  . Most correlated bigrams:\n",
      ". আওয় সভ\n",
      ". কর এনপ\n",
      "# 'Science_tech':\n",
      "  . Most correlated unigrams:\n",
      ". যবহ\n",
      ". সফটওয\n",
      "  . Most correlated bigrams:\n",
      ". গব ষক\n",
      ". যবহ রক\n",
      "# 'Sports':\n",
      "  . Most correlated unigrams:\n",
      ". টসম\n",
      ". উইক\n",
      "  . Most correlated bigrams:\n",
      ". হম দউল\n",
      ". অধ য়ক\n",
      "['International']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "LinearSVC                 0.683333\n",
       "LogisticRegression        0.614583\n",
       "MultinomialNB             0.512500\n",
       "RandomForestClassifier    0.462500\n",
       "Name: accuracy, dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Merge3.csv')\n",
    "df.head()\n",
    "from io import StringIO\n",
    "col = ['Category', 'Write']\n",
    "df = df[col]\n",
    "df = df[pd.notnull(df['Write'])]\n",
    "df.columns = ['Category', 'Write']\n",
    "df['category_id'] = df['Category'].factorize()[0]\n",
    "category_id_df = df[['Category', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['category_id', 'Category']].values)\n",
    "df.head()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='utf-8', ngram_range=(1, 2), stop_words=None)\n",
    "features = tfidf.fit_transform(df.Write).toarray()\n",
    "labels = df.category_id\n",
    "features.shape\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "N = 2\n",
    "for Category, category_id in sorted(category_to_id.items()):\n",
    "  features_chi2 = chi2(features, labels == category_id)\n",
    "  indices = np.argsort(features_chi2[0])\n",
    "  feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "  print(\"# '{}':\".format(Category))\n",
    "  print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
    "  print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Write'], df['Category'], random_state = 0)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "print(clf.predict(count_vect.transform([\"This company refuses to provide me verification and validation of debt per my right under the FDCPA. I do not believe this debt is mine.\"])))\n",
    "df[df['Write'] == \"This company refuses to provide me verification and validation of debt per my right under the FDCPA. I do not believe this debt is mine.\"]\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "  model_name = model.__class__.__name__\n",
    "  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "  for fold_idx, accuracy in enumerate(accuracies):\n",
    "    entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "cv_df.groupby('model_name').accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
